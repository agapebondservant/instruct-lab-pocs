{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "b0DO2AryfwGK"
   },
   "source": [
    "## Writing Articles with Agentic Workflows\n",
    "<link rel=\"stylesheet\"\n",
    "href=\"https://stackpath.bootstrapcdn.com/bootstrap/4.5.2/css/bootstrap.min.css\"\n",
    "integrity=\"sha384-JcKb8q3iqJ61gNV9KGb8thSsNjpSL0n8PARn9HuZOnIxN0hoP+VmmDGMN5t9UJ0Z\"\n",
    "crossorigin=\"anonymous\">\n",
    "<div class=\"bg-info\">\n",
    "<h3>What are agentic workflows?</h3>\n",
    "</div>\n",
    "\n",
    "An <b>agentic workflow</b> is a multi-step sequence of tasks or decisions whose orchestration is handled by AI agents. In Generative AI, AI agents are Large Language Models (or \"Large Action Models\" in this context) that can perform goal-oriented tasks with minimal human intervention. Such tasks may include everything from simple reasoning tasks to complex decision making, and often involve interaction with external resources or systems (called \"tools\").\n",
    "\n",
    "The following will build an agentic workflow for writing articles. The initial version of the workflow will consist of the following steps:\n",
    "\n",
    "\n",
    "1.   A **searcher** agent (LLM + search tool) which will search the web for relevant links based on user input.\n",
    "2.   An **outliner** node (LLM) which will generate a suitable outline for the article.\n",
    "3.   A **writer** node (LLM) which will generate the final article.\n",
    "4.   A **critic** node (LLM) which will critique the writer's output and provide feedback to the **writer** for improvements.\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "<div class=\"bg-info\">\n",
    "<h3>What is the difference between an agentic framework and an agentic orchestration framework?</h3>\n",
    "</div>\n",
    "\n",
    "There are different schools of thought about agentic orchestration frameworks.\n",
    "\n",
    "Agentic orchestration can refer to <b>agent-of-agent</b> systems, which are defined based on the number of agents. In this case, they are simply agentic systems that consist of more than a single agent. Hence, it can refer to agentic systems with multiple agents; it can also refer to agentic systems that invoke other agentic systems.\n",
    "\n",
    "Sometimes, agentic orchestration can also be used to distinguish complex multi-agent systems from simpler agentic systems. In this case, agentic orchestration is only necessary for systems with high levels of complexity. This is based on not just the number of agents, but other factors such as the types of flows (directed versus cyclic).\n",
    "\n",
    "There are many frameworks that can be used for building agentic workflows. Due to their reasoning and decision-making abilities, LLMs are a natural fit for driving autonomous workflows. However, users often want the ability to extend, constrain or even override aspects of the flow. For example, they may need a way to dynamically limit cycles, manage state across disparate tools, or integrate human-in-the-loop fedback. A popular approach is to use <b>LLM orchestration</b> frameworks. These are frameworks that combine the flexible and dynamic capabilities of agent-driven workflows with low-level control over essential details of the orchestration. This notebook uses <b>LangChain</b> to build the AI agents, and <b>LangGraph</b> to build the agentic workflow that orchestrates the agents.\n",
    "\n",
    "<div class=\"bg-info\">\n",
    "<h3>Workflow Summary</h3>\n",
    "</div>\n",
    "\n",
    "Steps of the Article Writer:\n",
    "- <i>Searcher</i> agent receives the article writing request from the user and executes a web search request. It is a tool-based agent, so it uses a tool for its search (indicated by tools in the diagram. The tool it uses is called Tavily - Tavily is a search engine agentic tool.)\n",
    "  - If it receives a tool invocation request, the workflow sends the request to the Tool Node (Tavily)\n",
    "  - Else, the workflow sends the search results to the Outliner agent.\n",
    "- <i>Outliner</i> agent receives the web search results from the Searcher agent and generates the article outline.\n",
    "  - The workflow sends the outline to the Writer agent.\n",
    "- <i>Writer</i> agent receives the outline from the Outliner agent (or the Critic agent - see below) and generates an article draft.\n",
    "  - The workflow sends the draft to the Critic agent.\n",
    "- <i>Critic</i> agent receives the article draft from the Writer agent and generates feedback about the article for the writer for suggested improvements.\n",
    "  - If the critic has no suggested improvements, the workflow ends.\n",
    "  - Else, it sends its suggested improvements back to the writer node."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "NBqxqZJ5dR8Y"
   },
   "source": [
    "#Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "mUakb41j7Si1"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/usr/bin/sh: line 1: apt: command not found\n",
      "  \u001b[1;31merror\u001b[0m: \u001b[1msubprocess-exited-with-error\u001b[0m\n",
      "  \n",
      "  \u001b[31m×\u001b[0m \u001b[32mBuilding wheel for pygraphviz \u001b[0m\u001b[1;32m(\u001b[0m\u001b[32mpyproject.toml\u001b[0m\u001b[1;32m)\u001b[0m did not run successfully.\n",
      "  \u001b[31m│\u001b[0m exit code: \u001b[1;36m1\u001b[0m\n",
      "  \u001b[31m╰─>\u001b[0m \u001b[31m[98 lines of output]\u001b[0m\n",
      "  \u001b[31m   \u001b[0m /tmp/pip-build-env-9mo5yw7d/overlay/lib/python3.11/site-packages/setuptools/config/_apply_pyprojecttoml.py:82: SetuptoolsDeprecationWarning: `project.license` as a TOML table is deprecated\n",
      "  \u001b[31m   \u001b[0m !!\n",
      "  \u001b[31m   \u001b[0m \n",
      "  \u001b[31m   \u001b[0m         ********************************************************************************\n",
      "  \u001b[31m   \u001b[0m         Please use a simple string containing a SPDX expression for `project.license`. You can also use `project.license-files`. (Both options available on setuptools>=77.0.0).\n",
      "  \u001b[31m   \u001b[0m \n",
      "  \u001b[31m   \u001b[0m         By 2026-Feb-18, you need to update your project and remove deprecated calls\n",
      "  \u001b[31m   \u001b[0m         or your builds will no longer be supported.\n",
      "  \u001b[31m   \u001b[0m \n",
      "  \u001b[31m   \u001b[0m         See https://packaging.python.org/en/latest/guides/writing-pyproject-toml/#license for details.\n",
      "  \u001b[31m   \u001b[0m         ********************************************************************************\n",
      "  \u001b[31m   \u001b[0m \n",
      "  \u001b[31m   \u001b[0m !!\n",
      "  \u001b[31m   \u001b[0m   corresp(dist, value, root_dir)\n",
      "  \u001b[31m   \u001b[0m /tmp/pip-build-env-9mo5yw7d/overlay/lib/python3.11/site-packages/setuptools/config/_apply_pyprojecttoml.py:61: SetuptoolsDeprecationWarning: License classifiers are deprecated.\n",
      "  \u001b[31m   \u001b[0m !!\n",
      "  \u001b[31m   \u001b[0m \n",
      "  \u001b[31m   \u001b[0m         ********************************************************************************\n",
      "  \u001b[31m   \u001b[0m         Please consider removing the following classifiers in favor of a SPDX license expression:\n",
      "  \u001b[31m   \u001b[0m \n",
      "  \u001b[31m   \u001b[0m         License :: OSI Approved :: BSD License\n",
      "  \u001b[31m   \u001b[0m \n",
      "  \u001b[31m   \u001b[0m         See https://packaging.python.org/en/latest/guides/writing-pyproject-toml/#license for details.\n",
      "  \u001b[31m   \u001b[0m         ********************************************************************************\n",
      "  \u001b[31m   \u001b[0m \n",
      "  \u001b[31m   \u001b[0m !!\n",
      "  \u001b[31m   \u001b[0m   dist._finalize_license_expression()\n",
      "  \u001b[31m   \u001b[0m /tmp/pip-build-env-9mo5yw7d/overlay/lib/python3.11/site-packages/setuptools/dist.py:759: SetuptoolsDeprecationWarning: License classifiers are deprecated.\n",
      "  \u001b[31m   \u001b[0m !!\n",
      "  \u001b[31m   \u001b[0m \n",
      "  \u001b[31m   \u001b[0m         ********************************************************************************\n",
      "  \u001b[31m   \u001b[0m         Please consider removing the following classifiers in favor of a SPDX license expression:\n",
      "  \u001b[31m   \u001b[0m \n",
      "  \u001b[31m   \u001b[0m         License :: OSI Approved :: BSD License\n",
      "  \u001b[31m   \u001b[0m \n",
      "  \u001b[31m   \u001b[0m         See https://packaging.python.org/en/latest/guides/writing-pyproject-toml/#license for details.\n",
      "  \u001b[31m   \u001b[0m         ********************************************************************************\n",
      "  \u001b[31m   \u001b[0m \n",
      "  \u001b[31m   \u001b[0m !!\n",
      "  \u001b[31m   \u001b[0m   self._finalize_license_expression()\n",
      "  \u001b[31m   \u001b[0m running bdist_wheel\n",
      "  \u001b[31m   \u001b[0m running build\n",
      "  \u001b[31m   \u001b[0m running build_py\n",
      "  \u001b[31m   \u001b[0m creating build/lib.linux-x86_64-cpython-311/pygraphviz\n",
      "  \u001b[31m   \u001b[0m copying pygraphviz/__init__.py -> build/lib.linux-x86_64-cpython-311/pygraphviz\n",
      "  \u001b[31m   \u001b[0m copying pygraphviz/agraph.py -> build/lib.linux-x86_64-cpython-311/pygraphviz\n",
      "  \u001b[31m   \u001b[0m copying pygraphviz/graphviz.py -> build/lib.linux-x86_64-cpython-311/pygraphviz\n",
      "  \u001b[31m   \u001b[0m copying pygraphviz/scraper.py -> build/lib.linux-x86_64-cpython-311/pygraphviz\n",
      "  \u001b[31m   \u001b[0m copying pygraphviz/testing.py -> build/lib.linux-x86_64-cpython-311/pygraphviz\n",
      "  \u001b[31m   \u001b[0m creating build/lib.linux-x86_64-cpython-311/pygraphviz/tests\n",
      "  \u001b[31m   \u001b[0m copying pygraphviz/tests/__init__.py -> build/lib.linux-x86_64-cpython-311/pygraphviz/tests\n",
      "  \u001b[31m   \u001b[0m copying pygraphviz/tests/test_attribute_defaults.py -> build/lib.linux-x86_64-cpython-311/pygraphviz/tests\n",
      "  \u001b[31m   \u001b[0m copying pygraphviz/tests/test_clear.py -> build/lib.linux-x86_64-cpython-311/pygraphviz/tests\n",
      "  \u001b[31m   \u001b[0m copying pygraphviz/tests/test_close.py -> build/lib.linux-x86_64-cpython-311/pygraphviz/tests\n",
      "  \u001b[31m   \u001b[0m copying pygraphviz/tests/test_drawing.py -> build/lib.linux-x86_64-cpython-311/pygraphviz/tests\n",
      "  \u001b[31m   \u001b[0m copying pygraphviz/tests/test_edge_attributes.py -> build/lib.linux-x86_64-cpython-311/pygraphviz/tests\n",
      "  \u001b[31m   \u001b[0m copying pygraphviz/tests/test_graph.py -> build/lib.linux-x86_64-cpython-311/pygraphviz/tests\n",
      "  \u001b[31m   \u001b[0m copying pygraphviz/tests/test_html.py -> build/lib.linux-x86_64-cpython-311/pygraphviz/tests\n",
      "  \u001b[31m   \u001b[0m copying pygraphviz/tests/test_layout.py -> build/lib.linux-x86_64-cpython-311/pygraphviz/tests\n",
      "  \u001b[31m   \u001b[0m copying pygraphviz/tests/test_node_attributes.py -> build/lib.linux-x86_64-cpython-311/pygraphviz/tests\n",
      "  \u001b[31m   \u001b[0m copying pygraphviz/tests/test_readwrite.py -> build/lib.linux-x86_64-cpython-311/pygraphviz/tests\n",
      "  \u001b[31m   \u001b[0m copying pygraphviz/tests/test_repr_mimebundle.py -> build/lib.linux-x86_64-cpython-311/pygraphviz/tests\n",
      "  \u001b[31m   \u001b[0m copying pygraphviz/tests/test_scraper.py -> build/lib.linux-x86_64-cpython-311/pygraphviz/tests\n",
      "  \u001b[31m   \u001b[0m copying pygraphviz/tests/test_string.py -> build/lib.linux-x86_64-cpython-311/pygraphviz/tests\n",
      "  \u001b[31m   \u001b[0m copying pygraphviz/tests/test_subgraph.py -> build/lib.linux-x86_64-cpython-311/pygraphviz/tests\n",
      "  \u001b[31m   \u001b[0m copying pygraphviz/tests/test_unicode.py -> build/lib.linux-x86_64-cpython-311/pygraphviz/tests\n",
      "  \u001b[31m   \u001b[0m running egg_info\n",
      "  \u001b[31m   \u001b[0m writing pygraphviz.egg-info/PKG-INFO\n",
      "  \u001b[31m   \u001b[0m writing dependency_links to pygraphviz.egg-info/dependency_links.txt\n",
      "  \u001b[31m   \u001b[0m writing top-level names to pygraphviz.egg-info/top_level.txt\n",
      "  \u001b[31m   \u001b[0m reading manifest file 'pygraphviz.egg-info/SOURCES.txt'\n",
      "  \u001b[31m   \u001b[0m reading manifest template 'MANIFEST.in'\n",
      "  \u001b[31m   \u001b[0m warning: no files found matching '*.swg'\n",
      "  \u001b[31m   \u001b[0m warning: no files found matching '*.png' under directory 'doc'\n",
      "  \u001b[31m   \u001b[0m warning: no files found matching '*.html' under directory 'doc'\n",
      "  \u001b[31m   \u001b[0m warning: no files found matching '*.txt' under directory 'doc'\n",
      "  \u001b[31m   \u001b[0m warning: no files found matching '*.css' under directory 'doc'\n",
      "  \u001b[31m   \u001b[0m warning: no previously-included files matching '*~' found anywhere in distribution\n",
      "  \u001b[31m   \u001b[0m warning: no previously-included files matching '*.pyc' found anywhere in distribution\n",
      "  \u001b[31m   \u001b[0m warning: no previously-included files matching '.svn' found anywhere in distribution\n",
      "  \u001b[31m   \u001b[0m no previously-included directories found matching 'doc/build'\n",
      "  \u001b[31m   \u001b[0m adding license file 'LICENSE'\n",
      "  \u001b[31m   \u001b[0m writing manifest file 'pygraphviz.egg-info/SOURCES.txt'\n",
      "  \u001b[31m   \u001b[0m copying pygraphviz/graphviz.i -> build/lib.linux-x86_64-cpython-311/pygraphviz\n",
      "  \u001b[31m   \u001b[0m copying pygraphviz/graphviz_wrap.c -> build/lib.linux-x86_64-cpython-311/pygraphviz\n",
      "  \u001b[31m   \u001b[0m running build_ext\n",
      "  \u001b[31m   \u001b[0m building 'pygraphviz._graphviz' extension\n",
      "  \u001b[31m   \u001b[0m creating build/temp.linux-x86_64-cpython-311/pygraphviz\n",
      "  \u001b[31m   \u001b[0m gcc -Wsign-compare -DDYNAMIC_ANNOTATIONS_ENABLED=1 -DNDEBUG -O2 -fexceptions -g -grecord-gcc-switches -pipe -Wall -Werror=format-security -Wp,-D_FORTIFY_SOURCE=2 -Wp,-D_GLIBCXX_ASSERTIONS -fstack-protector-strong -m64 -march=x86-64-v2 -mtune=generic -fasynchronous-unwind-tables -fstack-clash-protection -fcf-protection -D_GNU_SOURCE -fPIC -fwrapv -O2 -fexceptions -g -grecord-gcc-switches -pipe -Wall -Werror=format-security -Wp,-D_FORTIFY_SOURCE=2 -Wp,-D_GLIBCXX_ASSERTIONS -fstack-protector-strong -m64 -march=x86-64-v2 -mtune=generic -fasynchronous-unwind-tables -fstack-clash-protection -fcf-protection -D_GNU_SOURCE -fPIC -fwrapv -O2 -fexceptions -g -grecord-gcc-switches -pipe -Wall -Werror=format-security -Wp,-D_FORTIFY_SOURCE=2 -Wp,-D_GLIBCXX_ASSERTIONS -fstack-protector-strong -m64 -march=x86-64-v2 -mtune=generic -fasynchronous-unwind-tables -fstack-clash-protection -fcf-protection -D_GNU_SOURCE -fPIC -fwrapv -fPIC -DSWIG_PYTHON_STRICT_BYTE_CHAR -I/opt/app-root/include -I/usr/include/python3.11 -c pygraphviz/graphviz_wrap.c -o build/temp.linux-x86_64-cpython-311/pygraphviz/graphviz_wrap.o\n",
      "  \u001b[31m   \u001b[0m pygraphviz/graphviz_wrap.c:9: warning: \"SWIG_PYTHON_STRICT_BYTE_CHAR\" redefined\n",
      "  \u001b[31m   \u001b[0m     9 | #define SWIG_PYTHON_STRICT_BYTE_CHAR\n",
      "  \u001b[31m   \u001b[0m       |\n",
      "  \u001b[31m   \u001b[0m <command-line>: note: this is the location of the previous definition\n",
      "  \u001b[31m   \u001b[0m pygraphviz/graphviz_wrap.c:3023:10: fatal error: graphviz/cgraph.h: No such file or directory\n",
      "  \u001b[31m   \u001b[0m  3023 | #include \"graphviz/cgraph.h\"\n",
      "  \u001b[31m   \u001b[0m       |          ^~~~~~~~~~~~~~~~~~~\n",
      "  \u001b[31m   \u001b[0m compilation terminated.\n",
      "  \u001b[31m   \u001b[0m error: command '/usr/bin/gcc' failed with exit code 1\n",
      "  \u001b[31m   \u001b[0m \u001b[31m[end of output]\u001b[0m\n",
      "  \n",
      "  \u001b[1;35mnote\u001b[0m: This error originates from a subprocess, and is likely not a problem with pip.\n",
      "\u001b[31m  ERROR: Failed building wheel for pygraphviz\u001b[0m\u001b[31m\n",
      "\u001b[0m\u001b[31mERROR: Could not build wheels for pygraphviz, which is required to install pyproject.toml-based projects\u001b[0m\u001b[31m\n",
      "\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m23.2.1\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m25.1.1\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "# Install dependencies\n",
    "!apt install -qq libgraphviz-dev;\n",
    "!pip install -qU langgraph langgraph langchain_openai langchain_community python-dotenv langchain_mistralai llamaapi langchain-experimental langgraph-checkpoint langgraph-checkpoint-sqlite pygraphviz;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "XynJQl3jsZSe"
   },
   "outputs": [],
   "source": [
    "# Import libraries\n",
    "from typing import TypedDict, Literal\n",
    "import json\n",
    "import random\n",
    "from langgraph.graph import END, StateGraph\n",
    "from IPython.display import Image, display\n",
    "from langchain_core.runnables.graph import CurveStyle, MermaidDrawMethod\n",
    "from langchain_core.messages import HumanMessage\n",
    "import os\n",
    "from typing import Annotated, Literal, TypedDict\n",
    "from langgraph.graph.message import add_messages\n",
    "from langchain_community.tools.tavily_search import TavilySearchResults\n",
    "from langchain_core.prompts import ChatPromptTemplate, MessagesPlaceholder\n",
    "from langchain_openai import ChatOpenAI\n",
    "import functools\n",
    "from langgraph.prebuilt import ToolNode\n",
    "from langgraph.prebuilt import create_react_agent\n",
    "from langgraph.checkpoint.memory import MemorySaver\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "import time"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "CtrqsCjqn6X6"
   },
   "source": [
    "## Defining Templates\n",
    "Each agent has its own specific **template**. The templates are defined here."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "id": "wVN2oUbUn5J7"
   },
   "outputs": [],
   "source": [
    "searcher_template = \"\"\"\n",
    "Your job is to search the web for news that would be relevant for generating the article described by the user.\n",
    "\n",
    "NOTE: Do not write the article. Just search the web for related news if needed and then forward it to the outliner node.\n",
    "\"\"\"\n",
    "\n",
    "outliner_template = \"\"\"\n",
    "Your job is to take as input a list of articles from the web along with instructions from the user on what article they want to write and use that to\n",
    "generate an outline for the article.\n",
    "\"\"\"\n",
    "\n",
    "writer_template = \"\"\"Your job is to write an article using this format:\n",
    "\n",
    "    TITLE: <title>\n",
    "    BODY: <body>\n",
    "\n",
    "NOTE: Do not copy the outline. Just write the article but abide by the outline.\n",
    "```\n",
    "\"\"\"\n",
    "\n",
    "critic_template = \"\"\"Your job is to critique an article written by a writer. Please provide constructive critiques so the writer can improve it.\n",
    "\n",
    "```GUIDELINES:```\n",
    "\n",
    "  - Your feedback should be in bullet point format only.\n",
    "  - The critiques should only focus on are the use of keywords, the title of the article, and the title of the headers, also make sure they include references.\n",
    "  - NOTE: Do not write the article. Just provide feedback in bullet point format.\n",
    "  - NOTE: Do not include positive feedback.\n",
    "  - Never accept the first draft of the article.\n",
    "  - If you think the article looks good enough, say DONE.\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "-HnyBupj2ciz"
   },
   "source": [
    "## Defining State\n",
    "Here, we will define our **GraphState**, as well as the **nodes** and **edges** that our graph is comprised of. This will encapsulate **state** in our agentic workflows."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "id": "Tvdvlt-I13r4"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_14258/1807005728.py:13: LangChainDeprecationWarning: The class `TavilySearchResults` was deprecated in LangChain 0.3.25 and will be removed in 1.0. An updated version of the class exists in the :class:`~langchain-tavily package and should be used instead. To use it run `pip install -U :class:`~langchain-tavily` and import as `from :class:`~langchain_tavily import TavilySearch``.\n",
      "  google_search_tool = TavilySearchResults(max_results=5, include_answer=True, include_raw_content=True, include_images=True,)\n"
     ]
    },
    {
     "ename": "ValidationError",
     "evalue": "1 validation error for TavilySearchAPIWrapper\n  Value error, Did not find tavily_api_key, please add an environment variable `TAVILY_API_KEY` which contains it, or pass `tavily_api_key` as a named parameter. [type=value_error, input_value={}, input_type=dict]\n    For further information visit https://errors.pydantic.dev/2.11/v/value_error",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValidationError\u001b[0m                           Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[6], line 13\u001b[0m\n\u001b[1;32m      8\u001b[0m   messages: Annotated[\u001b[38;5;28mlist\u001b[39m, add_messages]\n\u001b[1;32m     10\u001b[0m \u001b[38;5;66;03m#####################################\u001b[39;00m\n\u001b[1;32m     11\u001b[0m \u001b[38;5;66;03m## TOOLS ##\u001b[39;00m\n\u001b[1;32m     12\u001b[0m \u001b[38;5;66;03m#####################################\u001b[39;00m\n\u001b[0;32m---> 13\u001b[0m google_search_tool \u001b[38;5;241m=\u001b[39m \u001b[43mTavilySearchResults\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmax_results\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m5\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minclude_answer\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minclude_raw_content\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minclude_images\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     15\u001b[0m \u001b[38;5;66;03m#####################################\u001b[39;00m\n\u001b[1;32m     16\u001b[0m \u001b[38;5;66;03m## AGENTS ##\u001b[39;00m\n\u001b[1;32m     17\u001b[0m \u001b[38;5;66;03m#####################################\u001b[39;00m\n\u001b[1;32m     18\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m     19\u001b[0m \u001b[38;5;124;03mThe LLMs used by the agents\u001b[39;00m\n\u001b[1;32m     20\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n",
      "File \u001b[0;32m/opt/app-root/lib64/python3.11/site-packages/langchain_core/_api/deprecation.py:222\u001b[0m, in \u001b[0;36mdeprecated.<locals>.deprecate.<locals>.finalize.<locals>.warn_if_direct_instance\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    220\u001b[0m     warned \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[1;32m    221\u001b[0m     emit_warning()\n\u001b[0;32m--> 222\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mwrapped\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/app-root/lib64/python3.11/site-packages/langchain_community/tools/tavily_search/tool.py:165\u001b[0m, in \u001b[0;36mTavilySearchResults.__init__\u001b[0;34m(self, **kwargs)\u001b[0m\n\u001b[1;32m    160\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtavily_api_key\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01min\u001b[39;00m kwargs:\n\u001b[1;32m    161\u001b[0m     kwargs[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mapi_wrapper\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m TavilySearchAPIWrapper(\n\u001b[1;32m    162\u001b[0m         tavily_api_key\u001b[38;5;241m=\u001b[39mkwargs[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtavily_api_key\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n\u001b[1;32m    163\u001b[0m     )\n\u001b[0;32m--> 165\u001b[0m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[38;5;21;43m__init__\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/app-root/lib64/python3.11/site-packages/langchain_core/tools/base.py:515\u001b[0m, in \u001b[0;36mBaseTool.__init__\u001b[0;34m(self, **kwargs)\u001b[0m\n\u001b[1;32m    510\u001b[0m     msg \u001b[38;5;241m=\u001b[39m (\n\u001b[1;32m    511\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124margs_schema must be a subclass of pydantic BaseModel or \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    512\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124ma JSON schema dict. Got: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mkwargs[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124margs_schema\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    513\u001b[0m     )\n\u001b[1;32m    514\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m(msg)\n\u001b[0;32m--> 515\u001b[0m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[38;5;21;43m__init__\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/app-root/lib64/python3.11/site-packages/langchain_core/load/serializable.py:130\u001b[0m, in \u001b[0;36mSerializable.__init__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    128\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__init__\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;241m*\u001b[39margs: Any, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs: Any) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    129\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"\"\"\"\u001b[39;00m  \u001b[38;5;66;03m# noqa: D419\u001b[39;00m\n\u001b[0;32m--> 130\u001b[0m     \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[38;5;21;43m__init__\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "    \u001b[0;31m[... skipping hidden 1 frame]\u001b[0m\n",
      "File \u001b[0;32m/opt/app-root/lib64/python3.11/site-packages/pydantic/main.py:253\u001b[0m, in \u001b[0;36mBaseModel.__init__\u001b[0;34m(self, **data)\u001b[0m\n\u001b[1;32m    251\u001b[0m \u001b[38;5;66;03m# `__tracebackhide__` tells pytest and some other tools to omit this function from tracebacks\u001b[39;00m\n\u001b[1;32m    252\u001b[0m __tracebackhide__ \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[0;32m--> 253\u001b[0m validated_self \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m__pydantic_validator__\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mvalidate_python\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdata\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mself_instance\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m    254\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m validated_self:\n\u001b[1;32m    255\u001b[0m     warnings\u001b[38;5;241m.\u001b[39mwarn(\n\u001b[1;32m    256\u001b[0m         \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mA custom validator is returning a value other than `self`.\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m'\u001b[39m\n\u001b[1;32m    257\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mReturning anything other than `self` from a top level model validator isn\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mt supported when validating via `__init__`.\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    258\u001b[0m         \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mSee the `model_validator` docs (https://docs.pydantic.dev/latest/concepts/validators/#model-validators) for more details.\u001b[39m\u001b[38;5;124m'\u001b[39m,\n\u001b[1;32m    259\u001b[0m         stacklevel\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m2\u001b[39m,\n\u001b[1;32m    260\u001b[0m     )\n",
      "\u001b[0;31mValidationError\u001b[0m: 1 validation error for TavilySearchAPIWrapper\n  Value error, Did not find tavily_api_key, please add an environment variable `TAVILY_API_KEY` which contains it, or pass `tavily_api_key` as a named parameter. [type=value_error, input_value={}, input_type=dict]\n    For further information visit https://errors.pydantic.dev/2.11/v/value_error"
     ]
    }
   ],
   "source": [
    "#####################################\n",
    "## STATE ##\n",
    "#####################################\n",
    "class NMAgentState(TypedDict):\n",
    "  \"\"\"\n",
    "  Encapsulates state in our agentic workflow\n",
    "  \"\"\"\n",
    "  messages: Annotated[list, add_messages]\n",
    "\n",
    "#####################################\n",
    "## TOOLS ##\n",
    "#####################################\n",
    "google_search_tool = TavilySearchResults(max_results=5, include_answer=True, include_raw_content=True, include_images=True,)\n",
    "\n",
    "#####################################\n",
    "## AGENTS ##\n",
    "#####################################\n",
    "\"\"\"\n",
    "The LLMs used by the agents\n",
    "\"\"\"\n",
    "granite_llm = ChatOpenAI(temperature=0,\n",
    "                         model=\"granite-3.2-8b-instruct\",\n",
    "                         request_timeout=240)\n",
    "\n",
    "def create_agent(llm, tools, system_message: str):\n",
    "    \"\"\"\n",
    "    Creates an agent with the given LLM, tools, and system message\n",
    "    \"\"\"\n",
    "    prompt = ChatPromptTemplate.from_messages(\n",
    "        [\n",
    "            (\n",
    "                \"system\",\n",
    "                \"{system_message}\",\n",
    "            ),\n",
    "            MessagesPlaceholder(variable_name=\"messages\"),\n",
    "        ]\n",
    "    )\n",
    "    prompt = prompt.partial(system_message=system_message)\n",
    "    if tools:\n",
    "      return prompt | llm.bind_tools(tools)\n",
    "    else:\n",
    "      return prompt | llm\n",
    "\n",
    "searcher_agent = create_agent(granite_llm, [google_search_tool], searcher_template)\n",
    "outliner_agent = create_agent(granite_llm, [], outliner_template)\n",
    "writer_agent = create_agent(granite_llm, [], writer_template)\n",
    "critic_agent = create_agent(granite_llm, [], critic_template)\n",
    "\n",
    "#####################################\n",
    "## NODES ##\n",
    "#####################################\n",
    "def agent_node(state, agent, name):\n",
    "  result = agent.invoke(state)\n",
    "  return { \"messages\": [result] }\n",
    "\n",
    "searcher_node = functools.partial(agent_node, agent=searcher_agent, name=\"Search Agent\")\n",
    "outliner_node = functools.partial(agent_node, agent=outliner_agent, name=\"Outliner Agent\")\n",
    "writer_node = functools.partial(agent_node, agent=writer_agent, name=\"Writer Agent\")\n",
    "tool_node = ToolNode([google_search_tool])\n",
    "critic_node = functools.partial(agent_node, agent=critic_agent, name=\"Critic Agent\")\n",
    "\n",
    "#####################################\n",
    "## EDGES ##\n",
    "#####################################\n",
    "def should_search(state) -> Literal['tools', 'outliner']:\n",
    "  if len(state['messages']) and state['messages'][-1].tool_calls:\n",
    "    return \"tools\"\n",
    "  else:\n",
    "    return \"outliner\"\n",
    "\n",
    "def should_edit(state) -> Literal['writer', END]:\n",
    "  if len(state['messages']) and 'DONE' in state['messages'][-1].content:\n",
    "    return END\n",
    "  else:\n",
    "    return \"writer\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "i8Lk_1C-8Qzd"
   },
   "source": [
    "## Defining the Workflow Graph\n",
    "Here, we will define the workflow, which will encapsulate the state, nodes and edges defined above."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "-7R8y42I8pjP"
   },
   "outputs": [],
   "source": [
    "workflow = StateGraph(NMAgentState)\n",
    "\n",
    "# nodes\n",
    "workflow.add_node(\"searcher\", searcher_node)\n",
    "workflow.add_node(\"outliner\", outliner_node)\n",
    "workflow.add_node(\"writer\", writer_node)\n",
    "workflow.add_node(\"tools\", tool_node)\n",
    "workflow.add_node(\"critic\", critic_node)\n",
    "\n",
    "# entrypoint\n",
    "workflow.set_entry_point(\"searcher\")\n",
    "\n",
    "# edges\n",
    "workflow.add_conditional_edges(\"searcher\", should_search)\n",
    "workflow.add_edge(\"tools\", \"searcher\")\n",
    "workflow.add_edge(\"outliner\", \"writer\")\n",
    "workflow.add_edge(\"writer\", 'critic')\n",
    "workflow.add_conditional_edges(\"critic\", should_edit)\n",
    "\n",
    "# compile the workflow into a graph\n",
    "checkpointer = MemorySaver()\n",
    "graph = workflow.compile(checkpointer=checkpointer, interrupt_before=['critic'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "aUg7mvnN-Ors"
   },
   "source": [
    "Visualize the graph:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 796
    },
    "id": "ztvmtR3S-QrM",
    "outputId": "40dae56c-8757-4428-b94b-49d2b732c12a"
   },
   "outputs": [],
   "source": [
    "display(Image(graph.get_graph().draw_png()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "YV-oh0rL-Vs7"
   },
   "source": [
    "# Testing the workflow\n",
    "Now that the workflow has been generated, we can test it out with different prompts."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "fN2Kzpwn-n5D"
   },
   "outputs": [],
   "source": [
    "# Prompt to test\n",
    "input = \"Generate an article about Cohesity's Global Support and Services.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "ih0KwOth_Ic2",
    "outputId": "2fb8e1eb-610d-4ca6-f98e-5a22cb3b9309"
   },
   "outputs": [],
   "source": [
    "config = {\"configurable\": {\"thread_id\": 12, \"recursion_limit\": 10}}\n",
    "try:\n",
    "  for event in graph.stream({\"messages\": [HumanMessage(content=input)]}, config, stream_mode=\"values\"):\n",
    "      event['messages'][-1].pretty_print()\n",
    "except Exception as e:\n",
    "  print(f\"\\n\\nErrors generating response:\\n===============\\n {str(e)}\")"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3.11",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
